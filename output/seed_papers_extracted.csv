title,authors,year,venue,doi,arxiv_id,url,abstract,why_seed,source_db,pdf_path,pdf_status,screening_id,pdf_hash,venue_type,game_type,open_ended,quantitative,llm_family,llm_role,eval_metrics,failure_modes,awscale,code_release,grey_lit_flag,extraction_status,extraction_confidence
Open-Ended Wargames with Large Language Models,"['Daniel P. Hogan', 'Andrea Brennen']",2024,arXiv preprint,,2404.11446,http://arxiv.org/abs/2404.11446,"Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames. We introduce ""Snow Globe,"" an LLM-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.","Foundational paper introducing Snow Globe framework for automating qualitative wargames with LLMs, bridging human and AI-conducted wargaming",arxiv,pdf_cache/pdfs/arxiv_2404_11446.pdf,downloaded_arxiv,SEED_0000,b07d4a6a2f5b3a9970dbd6441b002e1c6c299fdca119808d62fc3b950bd40796,tech-report,digital,yes,no,GPT-4,player,"The evaluation metrics are not explicitly detailed in the text, but the system is described as generating plausible narratives and handling adjudication, suggesting qualitative assessment of narrative coherence and logical consistency.",repetition|hallucination,5,none,yes,success,1.0
War and Peace (WarAgent): Large Language Model-based Multi-agent Simulation of World Wars,"['Wenyue Hua', 'Lizhou Fan', 'Lingyao Li', 'Kai Mei', 'Jianchao Ji', 'Yingqiang Ge', 'Libby Hemphill', 'Yongfeng Zhang']",2023,arXiv preprint,,2311.17227,http://arxiv.org/abs/2311.17227,"Can we avoid wars at the crossroads of history? This question has been pursued by individuals, scholars, policymakers, and organizations throughout human history. In this research, we attempt to answer the question by developing WarAgent, an LLM-powered multi-agent AI system, to simulate the participating countries (agents) in international conflicts under diverse scenarios. By situating in the historical context of World War I and trying to prevent the war, we demonstrate the feasibility of computational simulations for peace research and international relations studies. Our findings suggest that WarAgent can generate meaningful insights, despite being constrained by historical facts and the inherent limitations of LLMs. Specifically, we find that the different backgrounds and personalities of leader agents can significantly influence the simulation outcome. Additionally, our framework is highly adaptable, allowing it to simulate a wide range of conflict scenarios.",Multi-agent simulation framework for international conflicts and war prevention using LLMs in historical contexts,arxiv,pdf_cache/pdfs/arxiv_2311_17227.pdf,downloaded_arxiv,SEED_0001,d162a42c22c90495694bebf3402a782ce41acf845e52ca87dada44dc575f8dc2,tech-report,digital,yes,no,GPT-4,player,"Simulation effectiveness compared to historical events, analysis of triggers for war, exploration of historical inevitabilities.",,4,https://github.com/agiresearch/WarAgent,yes,success,1.0
Human vs. Machine: Behavioral Differences Between Expert Humans and Language Models in Wargame Simulations,"['Max Lamparth', 'Anthony Corso', 'Jacob Ganz', 'Oriana Skylar Mastro', 'Jacquelyn Schneider', 'Harold Trinkunas']",2024,arXiv preprint,,2403.03407,http://arxiv.org/abs/2403.03407,"To some, the advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness while reducing the influence of human error and emotions. However, there is still debate about how AI systems, especially large language models (LLMs) that can be applied to many tasks, behave compared to humans in high-stakes military decision-making scenarios with the potential for increased risks towards escalation. To test this potential and scrutinize the use of LLMs for such purposes, we use a new wargame experiment with 214 national security experts designed to examine crisis escalation in a fictional U.S.-China scenario and compare the behavior of human player teams to LLM-simulated team responses in separate simulations. Here, we find that the LLM-simulated responses can be more aggressive and significantly affected by changes in the scenario. We show a considerable high-level agreement in the LLM and human responses and significant quantitative and qualitative differences in individual actions and strategic tendencies.",Empirical comparative study of human vs. LLM behavior in military wargaming with 214 national security experts,arxiv,pdf_cache/pdfs/arxiv_2403_03407.pdf,downloaded_arxiv,SEED_0002,ec141b10f69c294248e6f7e669f896c9bb298b2bbf2d1d02d340217cb0d05544,tech-report,digital,yes,yes,"GPT-3.5, GPT-4",player,"High-level agreement between LLM and human responses, quantitative and qualitative differences in actions and strategic tendencies, behavioral consistency across moves.",aggressive behavior|lack of human empathy|inability to account for player background|dialog lacks quality|farcical harmony,2,https://github.com/ancorso/LLMWargaming,yes,success,1.0
