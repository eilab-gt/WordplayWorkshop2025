# Literature Review Pipeline Configuration
# Search config for LLM-powered open-ended wargaming & crisis sims
# Version: 3.0.0

# ============================================================================
# 0.  Administrative ----------------------------------------------------------------
version: 3.0.0
description: "Search config for LLM-powered open-ended wargaming & crisis sims"

# ============================================================================
# 1.  Temporal window ---------------------------------------------------------
search:
  years:
    start: 2022          # beginning of large-model era in wargaming
    end:   2025

  # Minimum LLM parameters (100M = GPT-2 baseline)
  llm_min_params: 100_000_000

  # Inclusion flags (papers must match at least one)
  inclusion_flags:
    - open_ended
    - quantitative

# ============================================================================
# 2.  Positive vocabulary -----------------------------------------------------
wargame_terms:
  # Core
  - "wargame*"
  - "war game*"
  - "war gaming"
  - "tabletop exercise*"
  - "TTX"
  - "seminar wargame*"
  - "policy game*"
  - "policy gaming"
  - "strategic game*"
  - "crisis game*"
  - "military exercise*"
  - "defen?e exercise*"
  - "red team*" # NEAR/5 (exercise OR simulation OR wargame OR campaign OR tabletop)
  # Matrix-wargame only
  - "matrix wargame*"
  - "matrix game*" # NEAR/5 (scenario OR crisis OR policy OR wargame OR tabletop OR seminar)
  # Crisis / policy / diplomacy
  - "crisis simulation*"
  - "crisis-management simulation*"
  - "military crisis simulation*"
  - "crisis decision-making exercise*"
  - "diplomacy simulation*"
  - "diplomatic game*"
  - "negotiation game*"
  - "negotiation simulation*"
  - "crisis-negotiation exercise*"
  - "policy simulation*"
  - "statecraft simulation*"
  - "Model Diplomacy"
  # Named LLM-wargame systems
  - "Snow Globe"
  - "WarAgent"
  # Chinese
  - "军事推演"        # military wargame
  - "危机模拟"        # crisis simulation

llm_terms:
  - "large language model*"
  - LLM
  - "foundation model*"
  - transformer*
  - "generative AI"
  - "generative artificial intelligence"
  # Specific models
  - GPT
  - GPT-3
  - GPT-3.5
  - GPT-4
  - ChatGPT
  - InstructGPT
  - Claude
  - "Claude-2"
  - "Claude-3"
  - PaLM
  - "PaLM-2"
  - Gemini
  - Bard
  - LLaMA
  - "LLaMA-2"
  - Alpaca
  - Vicuna
  - BERT
  - T5
  - Cicero
  # Agent terms
  - "AI agent"
  - "LLM agent"
  - "multi-agent"
  - "autonomous agent*"
  # Chinese
  - "大语言模型"
  - "生成式人工智能"

# ============================================================================
# 3.  Exclusion vocabulary (hard filters) ------------------------------------
exclusion_terms:
  # Game-theory noise
  - '"matrix game*" NEAR/5 (Nash OR equilibrium OR payoff OR "normal form" OR "game theory")'
  - AlphaZero
  - '"reinforcement learning" NEAR/5 (Go OR chess OR poker OR "board game" OR Atari)'
  # Red-teaming jailbreak noise
  - '"red teaming" NEAR/5 (LLM OR "language model" OR ChatGPT OR jailbreak OR prompt OR adversarial)'
  - "prompt injection"
  - "adversarial example"
  # Commentary / marketing
  - warontherocks.com
  - madsciblog.tradoc.army.mil
  - medium.com
  - substack.com
  - "press release"
  - "blog post"
  - newsletter
  - "vendor case study"
  - marketing
  - podcast
  # Social-sim & political noise
  - "opinion dynamics"
  - polarisation
  - politics
  - democracy
  - governance
  # Surveys & alignment (conditional block in §4)
  - "hallucination survey"
  - "alignment roadmap"
  # Medical simulation noise
  - hospital
  - medical
  - doctor
  - nurse

# ============================================================================
# 4.  Disambiguation rules (post-search regex) -------------------------------
disambiguation:
  matrix_game:
    negative_context: [Nash, equilibrium, payoff, "normal form", "game theory"]
  red_teaming:
    negative_context: [LLM, ChatGPT, jailbreak, prompt, "adversarial example", "prompt injection"]
  rl_board_game:
    negative_context: [AlphaZero, "board game", "Go game", chess, Atari]
  generic_surveys:
    negative_context: [survey, roadmap, hallucination, alignment]
    positive_required: [wargame, simulation, exercise, crisis, military]

# ============================================================================
# 5.  Grey-literature tagging -------------------------------------------------
grey_lit_sources:
  - ".mil"
  - ".gov"
  - ".nato.int"
  - warontherocks.com
  - madsciblog.tradoc.army.mil
  - paxsims.wordpress.com
  - think-tank

# ============================================================================
# 6.  Query strategies --------------------------------------------------------
query_strategies:
  primary:
    description: "Core Wargame × LLM query"
    template: |
      ({wargame_terms}) AND ({llm_terms}) NOT ({exclusion_terms})

  secondary:
    - description: "Policy / diplomacy simulations"
      template: |
        ("policy simulation*" OR "negotiation game*" OR "Model Diplomacy"
         OR "diplomacy simulation*" OR "crisis-negotiation exercise*")
        AND ({llm_terms}) NOT ({exclusion_terms})

    - description: "Grey-lit NATO / GOV PDFs"
      template: |
        ("wargame*" OR "simulation" OR "exercise")
        AND ("large language model" OR LLM OR ChatGPT OR GPT-4)
        AND (site:.gov OR site:.mil OR site:.nato.int)
        AND (filetype:pdf)
        NOT ({exclusion_terms})

# ============================================================================
# 7.  Source-specific limits --------------------------------------------------
source_optimizations:
  arxiv:
    categories: [cs.AI, cs.CL, cs.MA, cs.GT, cs.CY]
  semantic_scholar:
    fields: ["Computer Science", "Political Science", "Military Science"]
  google_scholar:
    include_patents: false
    include_citations: true

# ============================================================================
# 8.  Quality metrics ---------------------------------------------------------
quality_metrics:
  minimum_precision: 0.65
  target_recall: 0.9

# ============================================================================
# Original Production Settings (preserved from v2.0.0) -----------------------

# Action and role terms
action_terms:
  # Core actions
  - "simulation"
  - "simulate"
  - "simulating"
  - "play"
  - "playing"
  - "player"
  - "participant"
  - "agent"
  # Analysis and support
  - "analysis"
  - "analyze"
  - "evaluation"
  - "evaluate"
  - "assessment"
  - "decision support"
  - "decision-making support"
  - "planning"
  - "strategy"
  - "modeling"
  - "prediction"
  - "benchmark"
  # Generation and creation
  - "scenario generation"
  - "scenario creation"
  - "narrative generation"
  - "strategy generation"
  # Specific roles
  - "facilitator"
  - "moderator"
  - "adjudicator"
  - "opponent"
  - "advisor"
  - "assistant"
  # Behavioral terms
  - "escalation"
  - "de-escalation"
  - "negotiation"
  - "diplomacy"
  - "strategic planning"
  - "strategic reasoning"
  - "human-AI team"
  - "human-machine team"

# Failure Mode Vocabulary
failure_vocab:
  content:
    - bias
    - hallucination
    - factual_error
    - confabulation
    - inconsistency

  interactive:
    - escalation
    - deception
    - prompt_sensitivity
    - manipulation
    - adversarial

  security:
    - data_leakage
    - jailbreak
    - prompt_injection
    - privacy_breach

  other:
    - other
    - unspecified
    - unknown

# API Configuration
api_keys:
  semantic_scholar: "${SEMANTIC_SCHOLAR_API_KEY}"
  openai: "${OPENAI_API_KEY}"
  unpaywall_email: "${UNPAYWALL_EMAIL}"

# API Rate Limits - Production Scale
rate_limits:
  google_scholar:
    requests_per_hour: 500
    delay_seconds: 7.2
    burst_limit: 10

  semantic_scholar:
    requests_per_second: 50
    delay_milliseconds: 20
    burst_limit: 100

  arxiv:
    requests_per_second: 10
    delay_milliseconds: 100
    burst_limit: 25

  crossref:
    requests_per_second: 100
    delay_milliseconds: 10
    burst_limit: 200

# Paths
paths:
  cache_dir: "./pdf_cache"
  output_dir: "./output"
  data_dir: "./data"
  log_dir: "./logs"
  plugin_dir: "./plugins"

  # Session management
  progress_db: "./data/harvest_progress.db"
  session_cache: "./data/sessions"

  # Data files
  raw_papers: "./data/raw/papers_raw.csv"
  screening_progress: "./data/processed/screening_progress.csv"
  extraction_results: "./data/extracted/extraction.csv"

  # Database
  logging_db: "./logs/logging.db"

  # Backup
  backup_dir: "./backup"

# LLM Configuration
llm:
  model: "gpt-4o"
  temperature: 0.1
  max_tokens: 4000

  # System prompts
  extraction_prompt: |
    You are an expert at extracting structured information from academic papers about LLM-powered wargames.
    Extract the following fields based on the provided definitions:
    - venue_type: conference/journal/tech-report/workshop
    - game_type: seminar/matrix/digital/hybrid
    - open_ended: yes/no (based on definition of unconstrained natural-language moves)
    - quantitative: yes/no (tracks numeric scores/payoffs)
    - llm_family: The specific LLM used (e.g., GPT-4, Claude, Llama-70B)
    - llm_role: player/generator/analyst
    - eval_metrics: Description of evaluation metrics used
    - failure_modes: List of documented failure modes from the controlled vocabulary
    - code_release: GitHub URL or "none"
    - grey_lit_flag: true/false

    Return your response as a JSON object with these exact field names.

  awscale_prompt: |
    Rate this paper on the AWScale (Analytical<>Creative Scale) from 1-5:
    1 = Strictly analytic (deterministic tables, numeric payoff, no free narrative)
    2 = Mostly analytic (limited free text, heavy scoring)
    3 = Balanced (narrative <=> numeric balance)
    4 = Mostly creative (free-form moves, light scoring)
    5 = Wild-creative (storytelling, referee adjudication, emergent goals)

    Return only the number (1-5).

# Processing Configuration
processing:
  # Deduplication
  dedup:
    methods:
      - doi_exact
      - arxiv_id_exact
      - title_fuzzy
      - url_based
    title_similarity_threshold: 0.9
    enable_cross_source_dedup: true

  # PDF Processing
  pdf:
    max_file_size_mb: 100
    timeout_seconds: 60
    parallel_downloads: 20
    extract_images: false
    enable_caching: true
    cache_size_gb: 10

  # Batch sizes
  batch_sizes:
    harvesting: 1000
    pdf_download: 50
    llm_extraction: 20
    deduplication: 5000

# Production Settings
production:
  # Batch processing
  batch_size: 1000
  checkpoint_interval: 100
  max_concurrent_sources: 4

  # Resume capabilities
  enable_resume: true
  session_timeout_hours: 24

  # Error handling
  max_retries: 5
  backoff_factor: 2.0
  max_backoff_seconds: 300

  # Memory management
  max_papers_in_memory: 10000
  flush_interval: 1000

  # Monitoring
  enable_metrics: true
  metrics_interval: 60

  # Quality thresholds
  min_success_rate: 0.8
  max_error_rate: 0.1

# Visualization Configuration
visualization:
  # Output format
  format: "png"
  dpi: 300

  # Style
  style: "seaborn-v0_8-darkgrid"
  figsize: [10, 6]

  # Color scheme
  colors:
    game_types:
      seminar: "#1f77b4"
      matrix: "#ff7f0e"
      digital: "#2ca02c"
      hybrid: "#d62728"

    awscale:
      1: "#d62728"  # Red - Strictly analytic
      2: "#ff7f0e"  # Orange
      3: "#ffbb78"  # Light orange - Balanced
      4: "#2ca02c"  # Green
      5: "#1f77b4"  # Blue - Wild-creative

# Export Configuration
export:
  # Zenodo settings (optional)
  zenodo:
    enabled: false
    access_token: "${ZENODO_ACCESS_TOKEN}"
    community: "llm-wargames"

  # Archive settings
  compression: "zip"
  include_pdfs: false
  include_logs: true

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"

  # Multiple handlers
  handlers:
    - type: file
      filename: "logs/pipeline.log"
      max_bytes: 100000000  # 100MB
      backup_count: 10
    - type: file
      filename: "logs/errors.log"
      level: ERROR
      max_bytes: 50000000   # 50MB
      backup_count: 5
    - type: console
      level: INFO

  # SQLite logging
  db_schema:
    table: "pipeline_logs"
    retention_days: 30
    columns:
      - timestamp
      - module
      - function
      - status
      - message
      - error_trace

# Quality Control
quality:
  # Success rate monitoring
  min_source_success_rate: 0.8
  min_overall_success_rate: 0.9

  # Data quality thresholds
  min_confidence:
    title_match: 0.8
    pdf_extraction: 0.7
    llm_extraction: 0.6
    deduplication: 0.9

  # Validation rules
  validation:
    require_doi: false
    require_abstract: true
    min_abstract_length: 50
    min_year: 2022
    max_year: 2025
    max_title_length: 500

# Monitoring and Alerting
monitoring:
  enable_metrics: true
  metrics_port: 8080

  # Alert thresholds
  alerts:
    error_rate_threshold: 0.1
    success_rate_threshold: 0.8
    memory_usage_threshold: 0.9
    disk_usage_threshold: 0.9

  # Health checks
  health_check_interval: 300  # 5 minutes

  # Performance tracking
  track_performance: true
  performance_log: "logs/performance.log"

# Development Settings
development:
  debug: false
  dry_run: false
  sample_size: null  # Set to integer to limit processing
  use_cache: true
  parallel_workers: 8

# Backup and Recovery
backup:
  enable_auto_backup: true
  backup_interval_hours: 6
  retention_days: 30
  compress_backups: true

  # What to backup
  include:
    - progress_db
    - session_data
    - configuration
    - logs

  exclude:
    - pdf_cache
    - temporary_files

# Key venues to prioritize (from seed papers)
priority_venues:
  conferences:
    - "FAccT"  # Fairness, Accountability, and Transparency
    - "NeurIPS"
    - "ICML"
    - "AAAI"
    - "AAMAS"  # Autonomous Agents and Multiagent Systems
    - "CoG"    # IEEE Conference on Games

  journals:
    - "Science"
    - "Nature"
    - "International Security"
    - "Journal of Strategic Studies"
    - "Military Operations Research"
    - "Simulation & Gaming"
    - "Journal of Defense Modeling and Simulation"
    - "Computers in Human Behavior"

  preprint_servers:
    - "arXiv"
    - "SSRN"
    - "ResearchGate"

# Research groups and authors to track
key_contributors:
  groups:
    - "RAND Corporation"
    - "Center for Security and Emerging Technology (CSET)"
    - "Naval Postgraduate School MOVES Institute"
    - "MIT Security Studies Program"
    - "Meta Fundamental AI Research (FAIR)"

  authors:
    # From seed papers
    - "Daniel P. Hogan"
    - "Andrea Brennen"
    - "Jacquelyn Schneider"
    - "Max Lamparth"
    - "Juan-Pablo Rivera"
    - "Harold Trinkunas"
    - "Oriana Skylar Mastro"
