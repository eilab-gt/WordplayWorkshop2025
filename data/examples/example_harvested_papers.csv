title,authors,year,abstract,source_db,url,doi,arxiv_id,venue,citations,pdf_url,keywords
"Escalation Risks in LLM-Powered Wargaming: A First Assessment","Reddie, Andrew; Goldblum, Bethany; Laderman, Sarah; Trinkunas, Harold",2023,"This paper presents findings from a wargaming exercise exploring nuclear escalation risks when large language models participate in crisis simulations. We find that LLMs tend to escalate conflicts more readily than human players.","arxiv","https://arxiv.org/abs/2310.03857","","2310.03857","arXiv preprint",12,"https://arxiv.org/pdf/2310.03857.pdf","wargaming; LLM; escalation; nuclear"
"GPT-4 as Strategic Decision Maker in Military Simulations","Johnson, Michael; Smith, Karen",2024,"We evaluate GPT-4's performance as a strategic decision maker in complex military simulations, comparing its choices against expert human players and identifying systematic biases.","google_scholar","https://example.com/paper1","10.1234/jsec.2024.001","","Journal of Strategic Security",5,"","GPT-4; military; simulation; bias"
"Adversarial Red Teaming with Language Models","Chen, Lisa; Park, James",2023,"This study examines the use of large language models as red team adversaries in cybersecurity wargaming exercises, demonstrating both novel attack strategies and inherent limitations.","semantic_scholar","https://semanticscholar.org/paper/123456","10.1109/SPW.2023.00123","","IEEE Security & Privacy Workshops",18,"","red team; cybersecurity; LLM; adversarial"
"Human-AI Collaboration in Crisis Management Games","Williams, Sarah; Brown, Robert; Davis, Emily",2024,"We present a framework for human-AI collaboration in crisis management wargames, where LLMs serve as advisors to human decision makers, improving outcomes while maintaining human control.","crossref","https://doi.org/10.1177/1046878124123456","10.1177/1046878124123456","","Simulation & Gaming",3,"","crisis management; human-AI; collaboration; wargaming"
"Hallucination and Deception in AI Wargame Agents","Martinez, Carlos; Anderson, Jennifer",2023,"Analysis of hallucination patterns and deceptive behaviors exhibited by LLM agents in competitive wargaming scenarios, with implications for trust and verification.","arxiv","https://arxiv.org/abs/2308.12345","","2308.12345","arXiv preprint",7,"https://arxiv.org/pdf/2308.12345.pdf","hallucination; deception; trust; agent"
"Quantitative Scoring Methods for LLM Wargame Performance","Taylor, David; Wilson, Margaret",2024,"Development and validation of quantitative metrics for evaluating LLM performance in wargaming contexts, including decision quality, strategic coherence, and outcome optimization.","google_scholar","https://example.com/paper5","10.1080/12345678.2024.001","","Journal of Defense Modeling",2,"","metrics; evaluation; performance; quantitative"
"Open-Ended Naval Strategy Games with Transformer Models","Kim, Steve; Lee, Anna",2023,"Implementation of open-ended naval strategy wargames using transformer-based language models, allowing for emergent tactics and natural language command interfaces.","semantic_scholar","https://semanticscholar.org/paper/789012","","","Naval War College Review",9,"","naval; open-ended; transformer; strategy"
"Bias Mitigation in LLM-Powered Political-Military Games","Thompson, Mark; Garcia, Maria",2024,"Techniques for identifying and mitigating cultural and political biases in LLM behavior during political-military wargaming exercises.","crossref","https://doi.org/10.1145/3531234.3531456","10.1145/3531234.3531456","","ACM Conference on AI and Society",1,"","bias mitigation; political-military; fairness"