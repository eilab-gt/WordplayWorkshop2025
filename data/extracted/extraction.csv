screening_id,title,authors,year,venue,abstract,doi,url,source_db,include_ta,reason_ta,notes_ta,include_ft,reason_ft,notes_ft,relevance_score,quality_score,pdf_path,pdf_status,arxiv_id,citations,pdf_url,keywords,pdf_hash,screener_ta,screened_ta_date,screener_ft,screened_ft_date,potential_duplicate,language_detected,failure_modes,failure_modes_regex,llm_detected,game_type_detected,metrics_detected,code_detected
SCREEN_0005,VMAV-C: A Deep Attention-based Reinforcement Learning Algorithm for Model-based Control,Xingxing Liang; Qi Wang; Yanghe Feng; Zhong Liu; Jincai Huang,2018,,"Recent breakthroughs in Go play and strategic games have witnessed the great potential of reinforcement learning in intelligently scheduling in uncertain environment, but some bottlenecks are also encountered when we generalize this paradigm to universal complex tasks. Among them, the low efficiency of data utilization in model-free reinforcement algorithms is of great concern. In contrast, the model-based reinforcement learning algorithms can reveal underlying dynamics in learning environments and seldom suffer the data utilization problem. To address the problem, a model-based reinforcement learning algorithm with attention mechanism embedded is proposed as an extension of World Models in this paper. We learn the environment model through Mixture Density Network Recurrent Network(MDN-RNN) for agents to interact, with combinations of variational auto-encoder(VAE) and attention incorporated in state value estimates during the process of learning policy. In this way, agent can learn optimal policies through less interactions with actual environment, and final experiments demonstrate the effectiveness of our model in control problem.",,http://arxiv.org/abs/1812.09968v1,arxiv,yes,Strategic games mentioned,Test paper for extraction,yes,Strategic games mentioned,Test paper for full-text,,,error,1812.099681,,http://arxiv.org/pdf/1812.09968v1,cs.LG; cs.AI; cs.NE,,,,,,,en,,,,,,,
