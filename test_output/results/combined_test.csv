title,authors,year,abstract,source_db,url,doi,arxiv_id,venue,citations,pdf_url,keywords
Benchmarking Large Language Model (LLM) Performance for Game Playing via Tic-Tac-Toe,Oguzhan Topsakal; Jackson B. Harper,2024,"This study investigates the strategic decision-making abilities of large language models (LLMs) via the game of Tic-Tac-Toe, renowned for its straightforward rules and definitive outcomes. We developed a mobile application coupled with web services, facilitating gameplay among leading LLMs, including Jurassic-2 Ultra by AI21, Claude 2.1 by Anthropic, Gemini-Pro by Google, GPT-3.5-Turbo and GPT-4 by OpenAI, Llama2-70B by Meta, and Mistral Large by Mistral, to assess their rule comprehension and strategic thinking. Using a consistent prompt structure in 10 sessions for each LLM pair, we systematically collected data on wins, draws, and invalid moves across 980 games, employing two distinct prompt types to vary the presentation of the gameâ€™s status. Our findings reveal significant performance variations among the LLMs. Notably, GPT-4, GPT-3.5-Turbo, and Llama2 secured the most wins with the list prompt, while GPT-4, Gemini-Pro, and Mistral Large excelled using the illustration prompt. GPT-4 emerged as the top performer, achieving victory with the minimum number of moves and the fewest errors for both prompt types. This research introduces a novel methodology for assessing LLM capabilities using a game that can illuminate their strategic thinking abilities. Beyond enhancing our comprehension of LLM performance, this study lays the groundwork for future exploration into their utility in complex decision-making scenarios, offering directions for further inquiry and the exploration of LLM limits within game-based frameworks.",crossref,https://doi.org/10.3390/electronics13081532,10.3390/electronics13081532,,Electronics,0.0,,journal-article
Exploring Potential Prompt Injection Attacks in Federated Military LLMs and Their Mitigation,Youngjoon Lee; Taehyun Park; Yunho Lee; Jinu Gong; Joonhyuk Kang,2025,"Federated Learning (FL) is increasingly being adopted in military collaborations to develop Large Language Models (LLMs) while preserving data sovereignty. However, prompt injection attacks-malicious manipulations of input prompts-pose new threats that may undermine operational security, disrupt decision-making, and erode trust among allies. This perspective paper highlights four potential vulnerabilities in federated military LLMs: secret data leakage, free-rider exploitation, system disruption, and misinformation spread. To address these potential risks, we propose a human-AI collaborative framework that introduces both technical and policy countermeasures. On the technical side, our framework uses red/blue team wargaming and quality assurance to detect and mitigate adversarial behaviors of shared LLM weights. On the policy side, it promotes joint AI-human policy development and verification of security protocols. Our findings will guide future research and emphasize proactive strategies for emerging military contexts.",arxiv,http://arxiv.org/abs/2501.18416v1,,2501.184161,,,http://arxiv.org/pdf/2501.18416v1,cs.LG
The Prompt War: How AI Decides on a Military Intervention,Maxim Chupilkin,2025,"Which factors determine AI propensity for military intervention? While the use of AI in war games and military planning is growing exponentially, the simple analysis of key drivers embedded in the models has not yet been done. This paper does a simple conjoint experiment proposing a model to decide on military intervention in 640 vignettes where each was run for 100 times allowing to explore AI decision on military intervention systematically. The analysis finds that largest predictors of AI decision to intervene are high domestic support and high probability of success. Costs such as international condemnation, military deaths, civilian deaths, and negative economic effect are statistically significant, but their effect is around half of domestic support and probability of victory. Closing window of opportunity only reaches statistical significance in interaction with other factors. The results are remarkably consistent across scenarios and across different models (OpenAI GPT, Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.",arxiv,http://arxiv.org/abs/2507.06277v1,,2507.062771,,,http://arxiv.org/pdf/2507.06277v1,cs.CY; cs.AI
Wargaming as a Methodology: The International Crisis Wargame and Experimental Wargaming,Benjamin Schechter; Jacquelyn Schneider; Rachael Shaffer,2021,"Background. Wargaming has a long history as a tool for understanding the complexity of conflict. Although wargames have shown their relevance across topics and time, the immersive nature of wargames and the guild-like communities that surround them have often resisted the social scientific advances that occurred alongside the evolution of warfare. However, recent work raises new possibilities for integrating wargaming practices and social scientific methods. Purpose. Develop the experimental wargaming method and practice. Prioritizing the focus on iteration, control, and generalizability within experimental design can provide new opportunities for wargames to answer broader questions about decision-making, crisis behaviors, and patterns of outcomes. Method. The International Crisis Wargame developed in 2018 demonstrates the viability of experimental wargaming, and models the process of theorizing, designing, developing, and executing these wargames. It also identifies what makes games more or less experimental and details how experimental design influenced choices in the game. Conclusion. Experimental wargames are a promising new tool for both the social science and the wargaming communities. A proposed new research agenda for experimental design within wargames would support this nascent method",crossref,https://doi.org/10.1177/1046878120987581,10.1177/1046878120987581,,Simulation &amp; Gaming,16.0,https://journals.sagepub.com/doi/pdf/10.1177/1046878120987581,journal-article
WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models,Qiyue Yin; Pei Xu; Qiaozhe Li; Shengda Liu; Shengqi Shen; Tong Wang; Yihong Han; Xiaonan Zhao; Likun Yang; Shiyue Cao; Shiyu Qiu; Yuxuan Liu; Shizhao Yu; Lei Cui; Chengxin Yan; Jie Sun; Xiangquan Tang; Kaiqi Huang,2025,"Recent breakthroughs in Large Language Models (LLMs) have led to a qualitative leap in artificial intelligence' s performance on reasoning tasks, particularly demonstrating remarkable capabilities in mathematical, symbolic, and commonsense reasoning. However, as a critical component of advanced human cognition, strategic reasoning, i.e., the ability to assess multi-agent behaviors in dynamic environments, formulate action plans, and adapt strategies, has yet to be systematically evaluated or modeled. To address this gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark for LLMs using wargame as its evaluation environment. Wargame, a quintessential high-complexity strategic scenario, integrates environmental uncertainty, adversarial dynamics, and non-unique strategic choices, making it an effective testbed for assessing LLMs' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning. WGSR-Bench designs test samples around three core tasks, i.e., Environmental situation awareness, Opponent risk modeling and Policy generation, which serve as the core S-POE architecture, to systematically assess main abilities of strategic reasoning. Finally, an LLM-based wargame agent is designed to integrate these parts for a comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess the strengths and limitations of state-of-the-art LLMs in game-theoretic strategic reasoning and to advance research in large model-driven strategic intelligence.",arxiv,http://arxiv.org/abs/2506.10264v1,,2506.102641,,,http://arxiv.org/pdf/2506.10264v1,cs.AI
